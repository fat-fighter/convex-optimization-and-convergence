\documentclass{article}

\usepackage{paper}

\setpapertitle{Convergence of Gradient Descent and Its Variants}

\setauthor[150259]{Gurpreet Singh}{guggu@iitk.ac.in}
\addauthor[150300]{Jaivardhan Kapoor}{jkapoor@iitk.ac.in}

\newcommand{\x}[1]{\vx^{(#1)}}
\newcommand{\xs}{\vx^{\ast}}

\newcommand{\z}[1]{\vz^{(#1)}}
\newcommand{\zs}{\vz^{\ast}}

\newcommand{\f}[1]{f(\vx^{(#1)})}
\newcommand{\fs}{f(\vx^\ast)}

\newcommand{\fz}[1]{f(\z{#1})}
\newcommand{\fzs}{f(\zs)}

\newcommand{\gf}[1]{\nabla f(\vx^{(#1)})}
\newcommand{\ggf}{\nabla f(\vx)}

\newcommand{\gfz}[1]{\nabla \fz{#1}}
\newcommand{\ggfz}{\nabla f(\vz)}

\newcommand{\fpi}[2]{\func{\Pi_{#1}}{#2}}

\begin{document}
\makeheader
\rabstract{
	In this survey, we review a set of methods and techniques used to analyze the convergence of methods based around convex optimization using Gradient Descent and Stochastic Gradient Descent Variants.
}

\begin{psection}{Introduction}

	Gradient descent is an optimization algorithm used to minimize a function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. \citep{gd-overview}. Gradient Descent was formulated by \cite{gd-original} centuries ago. Many variants of this method have arrived, since, and are used in various fields.

	Gradient Descent is predominantly used in training Deep Networks. More specifically, variants of Gradient Descent with Stochastic Update rules are used.

	This articles aims to look at various variants of Gradient Descent and analyze the convergence of each variant in simple settings.

\end{psection}

	\begin{psection}{Preliminaries}

		\begin{psubsection}{Notation}

			We follow the general notation, where $\xs$ is an optimal point to be learned, \ie a local minima w.r.t. to a function, say $f : \cX \ra \bR$, where $\cX \subseteq \bR^d$ is the intersection of the domain set of $f$ and the feasible set of points. The point $\x{t}$ represents our approximation of the optimal point at a time step $t$.

			With an abuse of notation, we assume $\frac{\va}{\vM}$ to be the same as $\vM^{-1} \va$, where $\va \in \bR^d$ and $\vM \in \bR^{d \times d}$ and $\sqrt{(.)}$ or $(.)^{1/2}$ to be element-wise square root operators.

			We define a function $\Pi: \bR^d \to \cX$ as the projection operation with respect to a positive definite matrix $\vA$, such that
			\begin{equation}
				\func{\Pi_{\cX, \vA}}{\vx} = \argmin{\vz \in \cX} \norm{\vA^{1/2} \para{\vz - \vx}}_{2}
				\label{eq:pi}
			\end{equation}

		\end{psubsection}

		\begin{psubsection}{Convex Functions}

			Convexity of a function simplifies the complexity of optimization by inducing inequalities that are helpful for convergence. Below, we define the condition for a function to be convex.
			\begin{definition}[Convex Fucntion]
				\label{def:cvx}
				A function $f: \cX \ra \bR$ is said to be convex, iff $\qforall \vx, \vy \in \cX$,
				\begin{equation}
					f(\vy)	\qge	f(\vx) + \dotp{\nabla f(\vx)}{\vy - \vx}
					\label{eq:cvx}
				\end{equation}
			\end{definition}

			If a function $f : \cX \ra \bR$ is convex, then all the following inequalities are equivalent,

			\begin{enumerate}
				\item $\qforall \vx, \vy \in \cX$
					\begin{equation*}
						f(\vy)	\qge	f(\vx) + \dotp{\nabla f(\vx)}{\vy - \vx}
					\end{equation*}
				\item $\qforall \vx, \vy \in \cX$ and $\qforall \alpha \in \brac{0, 1}$
					\begin{equation}
						\quad f(\alpha \cdot \vx + \para{1 - \alpha} \cdot \vy)	\qle	\alpha \cdot f(\vx) + \para{1 - \alpha} \cdot f(\vy)
						\label{eq:cvx-alt}
					\end{equation}
				\item If $f$ is twice differentiable, then $\qforall \vx \in \cX$
					\begin{equation}
						\nabla^2 f(\vx)	\qsucceq 0
						\label{eq:cvx-2d}
					\end{equation}
			\end{enumerate}

			Below, we define two other inequalities, Strong Convexity and Strong Smoothness, that if a function satisfies, we can prove stronger convergence bounds for that function.
			\begin{definition}[Strong Convexity]
				\label{def:sc}
				A function $f: \cX \ra \bR$ is said to be $\alpha$-SC \footnote{$\alpha$-SC ($\alpha$-SS) denotes that the function is $\alpha$-Strongly Convex ($\alpha$-Strongly Smooth)} if $\qforall \vx, \vy \in \cX$,
				\begin{equation}
					f(\vy)	\qge	f(\vx) + \dotp{\nabla f(\vx)}{\vy - \vx} + \frac{\alpha}{2} \norm{\vy - \vx}_2
					\label{eq:sc}
				\end{equation}
			\end{definition}

			\begin{definition}[Strong Smoothness]
				\label{def:sc}
				A function $f: \cX \ra \bR$ is said to be $\alpha$-SS if $\qforall \vx, \vy \in \cX$,
				\begin{equation}
					f(\vy)	\qle	f(\vx) + \dotp{\nabla f(\vx)}{\vy - \vx} + \frac{\beta}{2} \norm{\vy - \vx}_2
					\label{eq:sc}
				\end{equation}
			\end{definition}

		\end{psubsection}

		We are now equipped with the basic tools sufficient to tackle the analysis of gradient based optimization methods. We discuss some of the deterministic methods in the next section, followed by Stochastic Methods of optimization in Section 4. The later sections deal with the noise variants of Gradient Descent methods, along with some comments on non-convex optimization.

	\end{psection}

\begin{psection}{Deterministic Methods}

	Deterministic Methods of optimization use the actual value of the function $f$ to compute the optimization step. We will discuss this in more detail when we discuss stochastic methods of optimization. We discuss three such methods of optimization, Vanilla Gradient Descent, Momentum and Nesterov's Accelerated Gradient Method and discuss their convergence under certain conditions.

	The algorithm for Vanilla Gradient Descent is given in Algorithm \hyperlink{algo:1}{1}. Most descent algorithms follow the same rules, with minor additions and improvements to the optimization (update) step. The function $h$ determines the form of the output, for example, $h$ can be an average function, \ie $h(\x{1} \dots \x{T}) = \frac{1}{T} \sum_{t = 1}^T \vx_t$, or we can simply set $h$ to return the last time step's estimate, \ie $h(\x{1} \dots \x{T}) = \x{T}$.

	\begin{algo}[0.9\textwidth]{Deterministic Gradient Descent}

		\bt{Input:} \quad Step sizes $\set{\eta_t > 0}_{t = 1}^T$ and a function $h : \cS \mapsto \cX $ where $\cS$ is a sequence of data points. \sbr

		\bt{Output:}\, $\hat{\vx} \in \cH$, where $\hat{\vx} = \func{h}{\vx^{(1)} \dots \vx^{(T)}}$ \sbr

		\bt{Steps:}

		\begin{enumerate}
			\item Initialize $\x{0} \in \cH$
			\item For $t = 1 \dots T$, do
				\begin{align}
					\vg_t		&\eq	\gf{t}							\nonumber				\\
					\z{t + 1}	&\eq	\x{t} - \alpha_t \cdot \vg_t	\tag{Optimization Step}	\\
					\x{t + 1}	&\eq	\func{\Pi_{\cX}}{\z{t + 1}}		\tag{Projection Step}
				\end{align}
			\item Return $\hat{\vx} = \func{h}{\x{1} \dots \x{T}}$
		\end{enumerate}

	\end{algo}

	\begin{psubsection}{Gradient Descent}

		Vanilla Gradient Descent iteratively solves the optimization problem, using the gradient of the function $f$ at a time step. The idea is to update the parameter $\vx$ in the opposite direction of the gradient of the optimization objective.

		The projection step ensures that the predictions remain within the feasible set of points, \ie $\vX$.

		In case of Vanilla Gradient Descent, the values of $\set{\alpha_t}_{t = 1}^T$ are kept to be equal to the step sizes. Therefore, the update step can be written as
		\begin{align}
			\x{t+1}	\eq	\fpi{\cX}{\x{t} - \eta_t \cdot \gf{t}}
			\tag{\st{Vanilla GD}}
			\label{eq:vgd}
		\end{align}

		In the follow subsections, we discuss the convergence and the necessary conditions required for this convergence for different settings for the optimizer function $f$.

		\begin{note}
			For the rest of the article, we use $\Phi_t$ to denote the difference between the $t$\tth estimate of the optimal point and the real optimal value, \ie $\f{t} - \fs$ and $\sD_t$ to denote the difference between the current point estimate and the optimal point, \ie $\norm{\x{t} - \xs}_2$
		\end{note}

		\begin{pssubsection}{When $f$ is Convex with Bounded Gradients}

			First, we state the result, and later we give the derivation for the result.

			\begin{theorem}
				If $f : \vX \to \bR$ is convex and $\qforall \vx \in \cX, \ggf$ exists, then for bounded gradients, we say
				\begin{align}
					\frac{1}{T} \sum_{t = 1}^T \Phi_t	\qle	\frac{1}{\sqrt{T}} \sD_0^2 \sG^2
					\label{eq:gd-cvx-bddg}
				\end{align}
				\label{th:gd-cvx-bddg}

				\begin{proof}
					From the convexity (equation \ref{eq:def-cvx}) of the function $f$, we have
					\begin{align*}
						\Phi_t	&\qle	\dotp{\gf{t}}{\x{t} - \xs} \\
								&\eq	\frac{1}{\eta} \dotp{\eta \cdot \gf{t}}{\x{t} - \xs}
					\end{align*}

					Here, we mention two properties, which will be used here, as well as a few times in later proofs

					\begin{property}
						For any two vectors $\va, \vb \in \bR^m$,
						\begin{equation}
							\norm{\va + \vb}_2^2 - \norm{\va}_2^2 - \norm{b}_2^2	\oeq{a}	2\dotp{a}{b}	\oeq{b}	\norm{\va}_2^2 + \norm{b}_2^2 - \norm{\va - \vb}_2^2
							\label{eq:dotp}
						\end{equation}
					\end{property}

					Using property \hyperref[eq:dotp]{\ref*{eq:dotp}a}, we can write the above inequality as
					\begin{align*}
						\Phi_t	&\qle	\frac{1}{2 \eta} \para{\norm{\x{t} - \xs}_2^2 + \eta^2 \norm{\gf{t}}_2^2 - \norm{\x{t} - \eta \cdot \gf{t} - \xs}} \\
								&\qle	\frac{1}{2 \eta} \para{\sD_t^2 + \eta^2 \sG^2 - \sD_{t + 1}^2} \\
								&\eq	\frac{1}{2 \eta} \para{\sD_t^2 - \sD_{t + 1}^2} + \frac{\eta}{2} \sG^2
					\end{align*}

					Adding for $t = 0 \dots T$, we get
					\begin{align*}
						\sum_{t = 0}^T	\Phi_t						&\qle	\frac{1}{2 \eta} \para{\sD_0^2 - \sD_{T+1}^2} + \frac{\eta\,T}{2} \cdot \sG^2 \\
						\implies \frac{1}{T} \sum_{t = 0}^T	\Phi_t	&\qle	\frac{1}{2 \eta \, T} \sD_0^2 + \frac{\eta}{2} \cdot \sG^2
					\end{align*}

					This proves theorem \ref{th:gd-cvx-bddg}
				\end{proof}
			\end{theorem}

			However, how does the above inequality ensure that gradient descent actually gives us a good estimate of the optimal point $\xs$? This can, in fact, be seen as another result of convexity in the function, since, using the convexity properties of $f$, we can claim
			\begin{align*}
				\func{f}{\frac{1}{T} \sum_{t = 1}^T \x{t}}	\qle	\sum_{t = 1}^T \f{t}
			\end{align*}

			Therefore, substituting this in equation \ref{eq:gd-cvx-bddg}, we can write
			\answer[0.7\textwidth]{
				\begin{equation}
					\func{f}{\frac{1}{T} \sum_{t = 1}^T \x{t}} - \fs	\qle	\frac{1}{2 \eta\, T} \sD_0^2 + \frac{\eta}{2} \cdot \sG^2
					\label{eq:gd-1-bound}
				\end{equation}
			}

			Hence for a case when the function $f$ is convex and has bounded gradients, we can say that This allows us to bound the value of $\Phi_T$ as $T$ increases, given the return function, \ie $h$ is an averaging function.

		\end{pssubsection}

		\begin{pssubsection}{When $f$ is Convex and $\vbeta$-Strongly Smooth}

			We now look at a more restrictive setting, in the sense that this setting allows us to have a much stronger bound than the bound given in equation \ref{eq:gd-1-bound}. Again, we state the result first, then give a convergence proof for the same. \sbr

			\begin{theorem}
				If $f : \vX \to \bR$ is convex, $\beta$-smooth and $\qforall x$, $\gf{t}$ exists, we can say
				\begin{align}
					\Phi_t	\qle	\frac{1}{2 \eta} \cdot \frac{\sD_0^2}{T}
					\label{eq:gd-cvx-bddg}
				\end{align}
				\label{th:gd-cvx-bddg}

				\begin{proof}
					From the convexity and smoothness of the function $f$, we have, respectively
					\begin{align}
						\fs			&\qge	\f{t} - \dotp{\gf{t}}{\x{t} - \xs} \label{eq:gd2-beta} \\
						\f{t + 1}	&\qle	\f{t} + \dotp{\gf{t}}{\x{t + 1} - \x{t}} + \frac{\beta}{2} \norm{\x{t + 1} - \x{t}}_2^2 \nonumber
					\end{align}

					From the update equation of Gradient Descent, we can replace $\x{t + 1}$ with $\x{t} - \eta_t \cdot \gf{t}$. Therefore, we get
					\begin{align}
						\f{t + 1}	&\qle	\f{t} + \para{\frac{\beta}{2} - \frac{1}{\eta_t}} \norm{\eta_t \cdot \gf{t}}_2^2 \label{eq:gd2-cvx}
					\end{align}

					Subtracting equation \ref{eq:gd2-beta} from \ref{eq:gd2-cvx}, we get
					\begin{align*}
						\Phi_{t + 1}	&\qle	\para{\frac{\beta}{2} - \frac{1}{\eta_t}} \norm{\eta_t \cdot \gf{t}}_2^2 - \dotp{\gf{t}}{\x{t} - \xs} \\
						&\eq	\para{\frac{\beta}{2} - \frac{1}{\eta_t}} \norm{\eta_t \cdot \gf{t}}_2^2 - \frac{1}{\eta_t} \dotp{\eta_t \cdot \gf{t}}{\x{t} - \xs}
					\end{align*}

					Using property \hyperref[eq:dotp]{\ref*{eq:dotp}a}, we can write this, similarly to the previous case, as
					\begin{align*}
						\Phi_{t + 1}	&\qle	\para{\frac{\beta}{2} - \frac{1}{\eta_t}} \norm{\eta_t \cdot \gf{t}}_2^2 + \frac{1}{2 \eta_t} \para{\sD_t^2 + \norm{\eta_t \cdot \gf{t}}_2^2 - \sD_{t + 1}^2} \\
						\Phi_{t + 1}	&\qle	\frac{1}{2 \eta_t} \para{\sD_t^2 - \sD_{t + 1}^2} + \para{\frac{\beta}{2} - \frac{1}{2 \eta_t}} \norm{\eta_t \cdot \gf{t}}_2^2
					\end{align*}

					Suppose if we set $\eta_t \le \frac{1}{\beta}$, then the second term is always positive. Hence, we can write
					\begin{align*}
						\Phi_t	\qle	\frac{1}{2 \eta_t} \para{\sD_t^2 - \sD_{t + 1}^2}
					\end{align*}

					Adding for $t = 0 \dots T$, we get
					\begin{align*}
						\sum_{t = 0}^T	\Phi_t						&\qle	\frac{1}{2 \eta_t} \para{\sD_0^2 - \sD_{T + 1}^2} \\
						\implies \frac{1}{T} \sum_{t = 0}^T	\Phi_t	&\qle	\frac{1}{2 \eta} \frac{\sD_0^2}{T}
					\end{align*}

					This completes the proof.
				\end{proof}
			\end{theorem}

			Therefore, we can see that this bound offers much more than the bound in the previous case, as we can see that for large values of $T$, the bound will tend towards 0, and hence we can be sure our estimate of $\fs$ is good.

			Also, similar to the previous case, we can write, using the properties of convexity,
			\answer{
				\begin{equation}
					\func{f}{\frac{1}{T} \sum_{t = 1}^T \x{t}}	\qle	\frac{1}{2 \eta} \cdot \frac{\sD_0^2}{T}
					\label{eq:gd-2-bound}
				\end{equation}
			}

		\end{pssubsection}

	\end{psubsection}

	\begin{psubsection}{Momentum}

		<++>

	\end{psubsection}

	\begin{psubsection}{Nesterov's Accelerated Gradient}

		For NAG, we consider the case where $f$ is convex and $\beta$-SS.

		\begin{theorem}
			\label{th:nag}
			If $f$ is convex and $\beta$-SS, then Nesterov Accelerated Gradient satisfies
			\begin{equation}
				\f{T} - \fs	\qle	\frac{2 \beta \sD_0^2}{(T - 1)^2}
				\label{eq:nag}
			\end{equation}

			\begin{proof}
				From the $\beta$-Smoothness of the function $f$, we have
				\begin{align}
					\f{t+1}	&\qle	\fz{t} + \dotp{\gfz{t}}{\x{t+1} - \z{t}} + \frac{\beta}{2} \norm{\x{t+1} - \z{t}}_2^2 \nonumber \\
					\implies \f{t+1}	&\qle	\fz{t} + \para{\frac{\beta}{2} - \frac{1}{\eta}} \norm{\x{t + 1} - \z{t}}_2^2 \label{eq:nag-beta-bound}
				\end{align}

				Using the convexity of function $f$, we can write
				\begin{align}
					f(\vx)	&\qge	\fz{t} + \dotp{\gfz{t}}{\vx - \z{t}} \nonumber \\
					\implies f(\vx)	&\qge	\fz{t} + \frac{1}{\eta} \dotp{\x{t+1} - \z{t}}{\vx - \z{t}} \label{eq:nag-cvx-bound}
				\end{align}

				using equations \ref{eq:nag-beta-bound} and \ref{eq:nag-cvx-bound}, we can say
				\begin{align}
					\f{t + 1} - f(\vx)	\qle	\para{\frac{\beta}{2} - \frac{1}{\eta}} \norm{\x{t + 1} - \z{t}}_2^2 - \frac{1}{\eta} \dotp{\x{t+1} - \z{t}}{\vx - \z{t}}
					\label{eq:nag-diff-bound}
				\end{align}

				We can now move on to find a bound similar to given in the theorem. First, note
				\begin{align*}
					\lambda_t^2 \cdot \Phi_{t + 1} - \lambda_{t - 1}^2 \cdot \Phi_{t}	&\eq	\lambda_t \cdot \para{\lambda_t \cdot \Phi_{t + 1} - \para{\lambda_t - 1} \cdot \Phi_t} \\
					&\eq	\lambda_t \cdot \para{\f{t + 1} - \fs} + \lambda_t \cdot \para{\lambda_t - 1} \para{\f{t + 1} - \f{t}}
				\end{align*}
				Since $\qforall t > 0$, $\lambda_t > 1$, using equation \ref{eq:nag-diff-bound}, we can derive the following inequality
				\begin{align*}
					\lambda_t^2 \cdot \Phi_{t + 1} - \lambda_{t - 1}^2 \cdot \Phi_{t}	&\qle	\lambda_t^2 \cdot \para{\frac{\beta}{2} - \frac{1}{\eta}} \norm{\x{t + 1} - \z{t}}_2^2 \ + \\
					&\hspace{2cm} + \ \frac{\lambda_t}{\eta} \cdot \dotp{\x{t+1} - \z{t}}{\xs + \para{\lambda_t - 1} \cdot \x{t} - \lambda_t \cdot \z{t}}
				\end{align*}

				Now, suppose we fix $\eta = 1 / \beta$. Therefore, we can rewrite the above inequality as
				\begin{align*}
					\lambda_t^2 \cdot \Phi_{t + 1} - \lambda_{t - 1}^2 \cdot \Phi_{t}	&\qle	- \frac{\beta}{2} \cdot \bigg( \norm{\lambda_t \cdot \para{\x{t + 1} - \z{t}}}_2^2 \ - \\
					&\hspace{2cm} - \ 2 \dotp{\lambda_t \cdot \para{\x{t+1} - \z{t}}}{\xs + \para{\lambda_t - 1} \cdot \x{t} - \lambda_t \cdot \z{t}} \bigg)
				\end{align*}

				From property \hyperref[eq:dotp]{\ref*{eq:dotp}b}, where $\va = \lambda_t \cdot \para{\x{t + 1} - \z{t}}$ and $b = \xs + \para{\lambda_t - 1} \cdot \x{t} - \lambda_t \cdot \z{t}$, we can write this as
				\begin{align}
					\lambda_t^2 \cdot \Phi_{t + 1} - \lambda_{t - 1}^2 \cdot \Phi_{t}	&\qle	- \frac{\beta}{2} \cdot \bigg( \norm{\lambda_t \cdot \x{t + 1} - \para{\lambda_t - 1} \cdot \x{t} - \xs}_2^2 \ - \nonumber \\
					&\hspace{3cm} - \ \norm{\lambda_t \cdot \z{t} - \para{\lambda_t - 1} \cdot \x{t} - \xs} \bigg)_2^2
					\label{eq:nag-diff}
				\end{align}

				Now, from the definition of $\z{t + 1}$, we can write
				\begin{align}
					\z{t + 1}	&\eq	\x{t + 1} + \gamma_t \cdot \para{\x{t} - \x{t + 1}} \nonumber \\
					\implies \lambda_{t + 1} \cdot \z{t + 1}	&\eq	\lambda_{t + 1} \cdot \x{t + 1} + \para{1 - \lambda_t} \cdot \para{\x{t } - \x{t + 1}} \nonumber \\
					\implies \lambda_{t + 1} \cdot \z{t + 1} - \para{\lambda_{t + 1} - 1} \cdot \x{t + 1}	&\eq	\lambda_t \cdot \x{t + 1} - \para{\lambda_t - 1} \cdot \x{t} \label{eq:nag-us}
				\end{align}

				We can substitute the term in equation \ref{eq:nag-diff} using equation \ref{eq:nag-us}. Now, define $\vu_t = \lambda_t \cdot \z{t} - \para{\lambda_t - 1} \cdot \x{t} - \xs$. Therefore, we can write
				\begin{align*}
					\lambda_t^2 \cdot \Phi_{t + 1} - \lambda_{t - 1}^2 \cdot \Phi_{t}	\qle	\frac{\beta}{2} \cdot \para{\norm{\vu_t}_2^2 - \norm{\vu_{t + 1}}_2^2}
				\end{align*}

				Adding this from $t = 0, 1 \dots (T - 1)$
				\begin{align*}
					\lambda_{T - 1}^2 \Phi_{T}	&\qle	\frac{\beta}{2} \cdot \para{\norm{\vu_0}_2^2 - \norm{\vu_T}_2^2} + \lambda_{0}^2 \cdot \Phi_{0}	\qle	\frac{\beta}{2} \cdot \norm{\vu_0}_2^2 + \lambda_0^2 \cdot \Phi_0
				\end{align*}

				We know $\lambda_0 = 0$. Also, using induction, it is easy to see that $\qforall t \ge 2$, $\lambda_{t} > t / 2$. therefore, we have
				\begin{align*}
					\Phi_T	\qle	\frac{2 \beta \cdot \norm{\vu_0}_2^2}{(T - 1)^2}	\eq	\frac{2 \beta \cdot \sD_0^2}{(T - 1)^2}
				\end{align*}
			\end{proof}
		\end{theorem}

	\end{psubsection}<++>

\end{psection}<++>

\begin{psection}{Adaptive Methods based on Exponentially Moving Averages}

	\begin{psubsection}{Stochastic Gradient Descent}
		\begin{equation}
			\tag{\st{SGD}}
			\func{\phi_t}{\vg_1 \dots \vg_t} \eq \vg_t \quad\text{and}\quad	\func{\psi_t}{\vg_1 \dots \vg_t} \eq \vI
		\end{equation}
	\end{psubsection}

	\begin{psubsection}{AdaGrad}
		\begin{align*}
			\tag{\st{AdaGrad}}
			\func{\phi_t}{\vg_1 \dots \vg_t} \eq \vg_t \quad\text{and}\quad	\func{\psi_t}{\vg_1 \dots \vg_t} \eq \frac{\tfunc{diag}{\sum_{i = 1}^t \vg_i^2}}{t}
		\end{align*}
	\end{psubsection}

	\begin{algo}[0.9\textwidth]{Generic Adaptive Method}

		\bt{Input:} \quad step size $\set{\alpha > 0}_{t = 1}^T$, and a sequence of functions $\set{\phi_t, \psi_t}_{t = 1}^T$ \sbr

		\bt{Output:}\, $\hat{\vx} \in \cH$, where $\hat{\vx} = \func{h}{\vx^{(1)} \dots \vx^{(T)}}$ \sbr

		\bt{Steps:}

		\begin{enumerate}
			\item Initialize $\vx^{(0)} \in \cH$
			\item For $t = 1 \dots T$, do
				\begin{align*}
					\vg_t				&\eq	\nabla \func{f_t}{x_t}						\\
					\vm_t			&\eq	\func{\phi_t}{\vg_1 \dots \vg_t}			\\
					V_t				&\eq	\func{\phi_t}{\vg_1 \dots \vg_t}			\\
					\vz^{(t + 1)}	&\eq	\vx^{(t)} - \alpha_t V_t^{- 1 / 2} \vm_t	\\
					\vx^{(t)}		&\eq	\func{\Pi_{\cH, V^{1/2}}}{\vz^{(t + 1)}}
				\end{align*}
			\item Return $\hat{\vx} = \func{h}{\vx^{(1)} \dots \vx^{(T)}}$
		\end{enumerate}

	\end{algo}

\end{psection}<++>

\bibliography{paper}
\bibliographystyle{plainnat}

\end{document}
